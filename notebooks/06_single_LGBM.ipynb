{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c282fb-5e5a-41d1-bad7-1231b8e57403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIGHTGBM\n",
      "================================================================================\n",
      "LightGBM: 4.6.0\n",
      "\n",
      "[1/6] Caricamento dati...\n",
      "‚úì Train: (58327370, 11)\n",
      "\n",
      "[2/6] Feature engineering\n",
      "  Date features...\n",
      "  Lag features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Lags: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rolling features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Rolling: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:10<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ID encoding...\n",
      "‚úì Features create: (58327370, 22)\n",
      "\n",
      "[3/6] Preparazione train/test...\n",
      "Train: (57473650, 22) (fino giorno 1884)\n",
      "Test:  (853720, 22) (ultimi 28 giorni)\n",
      "\n",
      "Features: 11\n",
      "Dopo dropna - Train: (55796700, 22), Test: (853720, 22)\n",
      "\n",
      "‚úÖ X_train: (55796700, 11)\n",
      "‚úÖ X_test: (853720, 11)\n",
      "\n",
      "[4/6] Training LightGBM...\n",
      "\n",
      "üöÄ Training...\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttrain's rmse: 2.65119\ttest's rmse: 2.36561\n",
      "[100]\ttrain's rmse: 2.53552\ttest's rmse: 2.23402\n",
      "[150]\ttrain's rmse: 2.51948\ttest's rmse: 2.21601\n",
      "[200]\ttrain's rmse: 2.50896\ttest's rmse: 2.21005\n",
      "[250]\ttrain's rmse: 2.49854\ttest's rmse: 2.20507\n",
      "[300]\ttrain's rmse: 2.48659\ttest's rmse: 2.20026\n",
      "[350]\ttrain's rmse: 2.47145\ttest's rmse: 2.1944\n",
      "[400]\ttrain's rmse: 2.46403\ttest's rmse: 2.19145\n",
      "[450]\ttrain's rmse: 2.45328\ttest's rmse: 2.18792\n",
      "[500]\ttrain's rmse: 2.44469\ttest's rmse: 2.18531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's rmse: 2.44469\ttest's rmse: 2.18531\n",
      "\n",
      "‚úÖ Training completato!\n",
      "  Best iteration: 500\n",
      "  Best RMSE: 2.19\n",
      "\n",
      "Top 10 features:\n",
      "     feature  importance\n",
      "  id_encoded        3470\n",
      "roll_mean_28        2178\n",
      "       month        2048\n",
      " roll_mean_7        1595\n",
      "        year        1209\n",
      "         day        1091\n",
      "      lag_28        1051\n",
      "   dayofweek         904\n",
      "      lag_42         821\n",
      "      lag_35         478\n",
      "\n",
      "[5/6] Generazione forecasts per submission...\n",
      "Serie totali: 30490\n",
      "  Preparazione eval data...\n",
      "  Preparazione ultimi valori per lag...\n",
      "  ‚úì Dizionario creato: 30490 serie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Forecasting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30490/30490 [08:15<00:00, 61.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Forecast array: (30490, 28)\n",
      "\n",
      "[6/6] Calcolo WRMSSE...\n",
      "\n",
      "‚úÖ WRMSSE: 0.8145\n",
      "\n",
      "Salvataggio risultati...\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LightGBM \n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from m5_wrmsse import wrmsse\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LIGHTGBM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "OUTPUT_DIR = Path(\"../data/lightgbm_results\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"LightGBM: {lgb.__version__}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CARICA DATI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[1/6] Caricamento dati...\")\n",
    "\n",
    "with open(DATA_DIR / \"train_official.pkl\", 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "print(f\"‚úì Train: {train.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[2/6] Feature engineering\")\n",
    "\n",
    "# Sort\n",
    "train = train.sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Date features\n",
    "print(\"  Date features...\")\n",
    "train['dayofweek'] = train['date'].dt.dayofweek\n",
    "train['day'] = train['date'].dt.day\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train['is_weekend'] = (train['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "# Lag features \n",
    "print(\"  Lag features...\")\n",
    "for lag in tqdm([28, 35, 42], desc=\"    Lags\"):\n",
    "    train[f'lag_{lag}'] = train.groupby('id')['sales'].shift(lag)\n",
    "\n",
    "# Rolling features\n",
    "print(\"  Rolling features...\")\n",
    "for window in tqdm([7, 28], desc=\"    Rolling\"):\n",
    "    train[f'roll_mean_{window}'] = train.groupby('id')['sales'].transform(\n",
    "        lambda x: x.shift(28).rolling(window).mean()\n",
    "    )\n",
    "\n",
    "# ID encoding\n",
    "print(\"  ID encoding...\")\n",
    "train['id_encoded'] = pd.factorize(train['id'])[0]\n",
    "\n",
    "print(f\"‚úì Features create: {train.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[3/6] Preparazione train/test...\")\n",
    "\n",
    "# Ultimi 28 giorni per test\n",
    "train['day_num'] = (train['date'] - train['date'].min()).dt.days\n",
    "\n",
    "TRAIN_END = train['day_num'].max() - 28\n",
    "\n",
    "X_train = train[train['day_num'] <= TRAIN_END].copy()\n",
    "X_test = train[train['day_num'] > TRAIN_END].copy()\n",
    "\n",
    "print(f\"Train: {X_train.shape} (fino giorno {TRAIN_END})\")\n",
    "print(f\"Test:  {X_test.shape} (ultimi 28 giorni)\")\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'dayofweek', 'day', 'month', 'year', 'is_weekend', 'id_encoded',\n",
    "    'lag_28', 'lag_35', 'lag_42',\n",
    "    'roll_mean_7', 'roll_mean_28'\n",
    "]\n",
    "\n",
    "print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "\n",
    "# Rimuovi NaN\n",
    "X_train = X_train.dropna(subset=feature_cols)\n",
    "X_test = X_test.dropna(subset=feature_cols)\n",
    "\n",
    "print(f\"Dopo dropna - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Separa\n",
    "y_train = X_train['sales']\n",
    "X_train_features = X_train[feature_cols]\n",
    "\n",
    "y_test = X_test['sales']\n",
    "X_test_features = X_test[feature_cols]\n",
    "\n",
    "print(f\"\\n‚úÖ X_train: {X_train_features.shape}\")\n",
    "print(f\"‚úÖ X_test: {X_test_features.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. LIGHTGBM TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[4/6] Training LightGBM...\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'poisson',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train_features, y_train)\n",
    "lgb_test = lgb.Dataset(X_test_features, y_test, reference=lgb_train)\n",
    "\n",
    "print(\"\\nüöÄ Training...\")\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[lgb_train, lgb_test],\n",
    "    valid_names=['train', 'test'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=30),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Training completato!\")\n",
    "print(f\"  Best iteration: {model.best_iteration}\")\n",
    "print(f\"  Best RMSE: {model.best_score['test']['rmse']:.2f}\")\n",
    "\n",
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importance()\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features:\")\n",
    "print(importance.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 6. FORECAST SU TUTTE LE SERIE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[5/6] Generazione forecasts per submission...\")\n",
    "\n",
    "# Carica ordine originale\n",
    "sales_orig = pd.read_csv(RAW_DIR / \"sales_train_evaluation.csv\")\n",
    "series_order = sales_orig['id'].tolist()\n",
    "\n",
    "print(f\"Serie totali: {len(series_order)}\")\n",
    "\n",
    "# Carica eval data\n",
    "with open(DATA_DIR / \"eval_official.pkl\", 'rb') as f:\n",
    "    eval_data = pickle.load(f)\n",
    "\n",
    "# Prepara eval data con stesse features\n",
    "print(\"  Preparazione eval data...\")\n",
    "eval_data = eval_data.sort_values(['id', 'date']).reset_index(drop=True)\n",
    "eval_data['dayofweek'] = eval_data['date'].dt.dayofweek\n",
    "eval_data['day'] = eval_data['date'].dt.day\n",
    "eval_data['month'] = eval_data['date'].dt.month\n",
    "eval_data['year'] = eval_data['date'].dt.year\n",
    "eval_data['is_weekend'] = (eval_data['dayofweek'] >= 5).astype(int)\n",
    "eval_data['id_encoded'] = pd.factorize(eval_data['id'])[0]\n",
    "\n",
    "# Crea dizionario per ultimi valori training per serie \n",
    "print(\"  Preparazione ultimi valori per lag...\")\n",
    "last_values_dict = (\n",
    "    X_train.groupby('id')['sales']\n",
    "    .apply(lambda x: x.tail(60).values)\n",
    "    .to_dict()\n",
    ")\n",
    "print(f\"  ‚úì Dizionario creato: {len(last_values_dict)} serie\")\n",
    "\n",
    "del train, X_test, y_test, X_test_features\n",
    "gc.collect()\n",
    "\n",
    "# Genera forecasts\n",
    "all_forecasts = []\n",
    "\n",
    "for series_id in tqdm(series_order, desc=\"Forecasting\"):\n",
    "    eval_series = eval_data[eval_data['id'] == series_id].copy()\n",
    "    \n",
    "    if len(eval_series) == 0 or series_id not in last_values_dict:\n",
    "        # Serie non vista: forecast = 0\n",
    "        all_forecasts.append(np.zeros(28))\n",
    "        continue\n",
    "    \n",
    "    # Prendi ultimi valori per lag\n",
    "    last_vals = last_values_dict[series_id]\n",
    "    \n",
    "    # Calcola lag features per eval\n",
    "    eval_series['lag_28'] = last_vals[-28] if len(last_vals) >= 28 else 0\n",
    "    eval_series['lag_35'] = last_vals[-35] if len(last_vals) >= 35 else 0\n",
    "    eval_series['lag_42'] = last_vals[-42] if len(last_vals) >= 42 else 0\n",
    "    \n",
    "    # Rolling features\n",
    "    eval_series['roll_mean_7'] = np.mean(last_vals[-35:-28]) if len(last_vals) >= 35 else 0\n",
    "    eval_series['roll_mean_28'] = np.mean(last_vals[-56:-28]) if len(last_vals) >= 56 else 0\n",
    "    \n",
    "    # Predict\n",
    "    X_eval = eval_series[feature_cols].fillna(0)\n",
    "    preds = model.predict(X_eval, num_iteration=model.best_iteration)\n",
    "    preds = np.maximum(preds, 0)[:28]  # Solo primi 28 e non-negative\n",
    "    \n",
    "    # Pad se necessario\n",
    "    if len(preds) < 28:\n",
    "        preds = np.pad(preds, (0, 28 - len(preds)), constant_values=0)\n",
    "    \n",
    "    all_forecasts.append(preds)\n",
    "\n",
    "# Converti in array (30490, 28)\n",
    "forecast_array = np.array(all_forecasts)\n",
    "print(f\"\\n‚úÖ Forecast array: {forecast_array.shape}\")\n",
    "\n",
    "# Check NaN\n",
    "nan_count = np.isnan(forecast_array).sum()\n",
    "if nan_count > 0:\n",
    "    print(f\"‚ö†Ô∏è  {nan_count} NaN trovati, riempimento con 0...\")\n",
    "    forecast_array = np.nan_to_num(forecast_array, nan=0.0)\n",
    "\n",
    "# ============================================================================\n",
    "# 7. CALCOLO WRMSSE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[6/6] Calcolo WRMSSE...\")\n",
    "\n",
    "wrmsse_score = wrmsse(forecast_array)\n",
    "\n",
    "print(f\"\\n‚úÖ WRMSSE: {wrmsse_score:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. SALVATAGGIO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nSalvataggio risultati...\")\n",
    "\n",
    "model.save_model(str(OUTPUT_DIR / 'lightgbm_model.txt'))\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_array, index=series_order)\n",
    "forecast_df.to_pickle(OUTPUT_DIR / 'lightgbm_forecasts.pkl')\n",
    "\n",
    "importance.to_csv(OUTPUT_DIR / 'feature_importance.csv', index=False)\n",
    "\n",
    "summary = {\n",
    "    'wrmsse': wrmsse_score,\n",
    "    'best_iteration': model.best_iteration,\n",
    "    'best_rmse': model.best_score['test']['rmse'],\n",
    "    'n_series': len(series_order),\n",
    "    'n_features': len(feature_cols),\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'lightgbm_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ca02c-c508-4f2b-9f05-17707a36f41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af2ac3-7c56-4367-bd41-725fdf256f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_env",
   "language": "python",
   "name": "mlops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
