{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2806bdf-2e2a-4442-bfbf-90d773fadbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Hierarchical LightGBM \n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings, gc, pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from m5_wrmsse import wrmsse \n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) SETUP\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "OUT_DIR = Path(\"../data/hier_fast_results\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FAST_HISTORY_DAYS = 600\n",
    "LAGS = [7, 14, 28]\n",
    "ROLLS = [7, 14, 28]\n",
    "N_ROUNDS = 200\n",
    "\n",
    "print(\"Config FAST:\")\n",
    "print(f\"- History days: {FAST_HISTORY_DAYS}\")\n",
    "print(f\"- Lags: {LAGS}, Rolling: {ROLLS}\")\n",
    "print(f\"- Rounds: {N_ROUNDS}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) CARICAMENTO DATI\n",
    "# ----------------------------------------------------------------------------\n",
    "calendar = pd.read_csv(RAW_DIR / \"calendar.csv\",\n",
    "                       usecols=[\"date\",\"d\",\"wm_yr_wk\",\"wday\",\"month\",\"year\",\n",
    "                                \"snap_CA\",\"snap_TX\",\"snap_WI\"])\n",
    "prices = pd.read_csv(RAW_DIR / \"sell_prices.csv\",\n",
    "                     usecols=[\"store_id\",\"item_id\",\"wm_yr_wk\",\"sell_price\"])\n",
    "sales = pd.read_csv(RAW_DIR / \"sales_train_evaluation.csv\")\n",
    "\n",
    "# Riduci sales alle ultime FAST_HISTORY_DAYS + 28\n",
    "d_cols = [c for c in sales.columns if c.startswith(\"d_\")]\n",
    "d2date = dict(zip(calendar[\"d\"], calendar[\"date\"]))\n",
    "dates = pd.to_datetime([d2date[d] for d in d_cols])\n",
    "last_date = dates.max()\n",
    "keep_mask = dates >= (last_date - pd.Timedelta(days=FAST_HISTORY_DAYS + 28))\n",
    "keep_cols = [c for c, m in zip(d_cols, keep_mask) if m]\n",
    "sales_small = pd.concat([sales[sales.columns[:6]], sales[keep_cols]], axis=1)\n",
    "\n",
    "# Melt \n",
    "long = sales_small.melt(id_vars=[\"id\",\"item_id\",\"dept_id\",\"cat_id\",\"store_id\",\"state_id\"],\n",
    "                        var_name=\"d\", value_name=\"sales\")\n",
    "long = long.merge(calendar[[\"d\",\"date\",\"wm_yr_wk\",\"wday\",\"month\",\"year\",\n",
    "                            \"snap_CA\",\"snap_TX\",\"snap_WI\"]],\n",
    "                  on=\"d\", how=\"left\")\n",
    "long[\"date\"] = pd.to_datetime(long[\"date\"])\n",
    "long = long.merge(prices, on=[\"store_id\",\"item_id\",\"wm_yr_wk\"], how=\"left\")\n",
    "\n",
    "# SNAP unico\n",
    "long[\"snap\"] = 0\n",
    "long.loc[(long[\"state_id\"]==\"CA\") & (long[\"snap_CA\"]==1),\"snap\"]=1\n",
    "long.loc[(long[\"state_id\"]==\"TX\") & (long[\"snap_TX\"]==1),\"snap\"]=1\n",
    "long.loc[(long[\"state_id\"]==\"WI\") & (long[\"snap_WI\"]==1),\"snap\"]=1\n",
    "\n",
    "# Tenere solo colonne utili immediate\n",
    "long = long[[\"id\",\"item_id\",\"dept_id\",\"cat_id\",\"store_id\",\"state_id\",\n",
    "             \"date\",\"sales\",\"sell_price\",\"wday\",\"month\",\"year\",\"snap\"]].copy()\n",
    "\n",
    "# Cut finale: storico FAST_HISTORY_DAYS + 28 test\n",
    "max_date = long[\"date\"].max()\n",
    "cut_date = max_date - pd.Timedelta(days=28)\n",
    "hist_start = cut_date - pd.Timedelta(days=FAST_HISTORY_DAYS)\n",
    "long = long[(long[\"date\"]>=hist_start) & (long[\"date\"]<=max_date)].copy()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) FEATURE ENGINEERING \n",
    "# ----------------------------------------------------------------------------\n",
    "assert \"sales\" in long.columns, \"Colonna 'sales' mancante prima del FE\"\n",
    "\n",
    "# Encodings categorici\n",
    "for c in [\"state_id\",\"store_id\",\"dept_id\",\"item_id\"]:\n",
    "    long[c+\"_enc\"] = pd.factorize(long[c])[0]\n",
    "\n",
    "# Date features leggere\n",
    "long[\"is_weekend\"] = long[\"wday\"].isin([1,7]).astype(int)\n",
    "\n",
    "def add_group_lag_roll(df, key_cols, val_col, prefix):\n",
    "    df = df.sort_values(key_cols + [\"date\"])\n",
    "    grp = df.groupby(key_cols, sort=False)[val_col]\n",
    "    for lag in LAGS:\n",
    "        df[f\"{prefix}_lag_{lag}\"] = grp.shift(lag).values\n",
    "    for w in ROLLS:\n",
    "        df[f\"{prefix}_roll_{w}\"] = grp.shift(1).rolling(w).mean().values\n",
    "    return df\n",
    "\n",
    "# 3.1) Bottom level lags/rolls su 'id' usando 'sales' (resta nel main DF)\n",
    "long = add_group_lag_roll(long, [\"id\"], \"sales\", \"b\")\n",
    "\n",
    "# 3.2) Item level: medie per (item_id, date) -> DF separato, prefissi 'it_'\n",
    "item_agg = (\n",
    "    long.groupby([\"item_id\",\"date\"], as_index=False)[\"sales\"]\n",
    "        .mean()\n",
    "        .rename(columns={\"sales\":\"sales_item\"})\n",
    ")\n",
    "item_agg = add_group_lag_roll(item_agg, [\"item_id\"], \"sales_item\", \"it\")\n",
    "item_agg_keep = [\"item_id\",\"date\"] + [c for c in item_agg.columns if c.startswith(\"it_\")]\n",
    "long = long.merge(item_agg[item_agg_keep], on=[\"item_id\",\"date\"], how=\"left\")\n",
    "\n",
    "# 3.3) Dept-Store level: medie per (dept_id, store_id, date) -> 'ds_'\n",
    "ds_agg = (\n",
    "    long.groupby([\"dept_id\",\"store_id\",\"date\"], as_index=False)[\"sales\"]\n",
    "        .mean()\n",
    "        .rename(columns={\"sales\":\"sales_dept_store\"})\n",
    ")\n",
    "ds_agg = add_group_lag_roll(ds_agg, [\"dept_id\",\"store_id\"], \"sales_dept_store\", \"ds\")\n",
    "ds_agg_keep = [\"dept_id\",\"store_id\",\"date\"] + [c for c in ds_agg.columns if c.startswith(\"ds_\")]\n",
    "long = long.merge(ds_agg[ds_agg_keep], on=[\"dept_id\",\"store_id\",\"date\"], how=\"left\")\n",
    "\n",
    "# 3.4) State-Store level: medie per (state_id, store_id, date) -> 'ss_'\n",
    "ss_agg = (\n",
    "    long.groupby([\"state_id\",\"store_id\",\"date\"], as_index=False)[\"sales\"]\n",
    "        .mean()\n",
    "        .rename(columns={\"sales\":\"sales_state_store\"})\n",
    ")\n",
    "ss_agg = add_group_lag_roll(ss_agg, [\"state_id\",\"store_id\"], \"sales_state_store\", \"ss\")\n",
    "ss_agg_keep = [\"state_id\",\"store_id\",\"date\"] + [c for c in ss_agg.columns if c.startswith(\"ss_\")]\n",
    "long = long.merge(ss_agg[ss_agg_keep], on=[\"state_id\",\"store_id\",\"date\"], how=\"left\")\n",
    "\n",
    "assert \"sales\" in long.columns, \"'sales' è stato perso dopo i merge\"\n",
    "\n",
    "# Cleanup\n",
    "del item_agg, ds_agg, ss_agg\n",
    "gc.collect()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) SPLIT TRAIN/TEST E FEATURE SET\n",
    "# ----------------------------------------------------------------------------\n",
    "train_df = long[long[\"date\"]<=cut_date].copy()\n",
    "test_df  = long[long[\"date\"]> cut_date].copy()\n",
    "\n",
    "base_feats = [\"wday\",\"month\",\"year\",\"is_weekend\",\"snap\",\n",
    "              \"sell_price\",\"state_id_enc\",\"store_id_enc\",\"dept_id_enc\",\"item_id_enc\"]\n",
    "\n",
    "lag_feats  = [f\"b_lag_{l}\"  for l in LAGS] + [f\"it_lag_{l}\" for l in LAGS] + \\\n",
    "             [f\"ds_lag_{l}\" for l in LAGS] + [f\"ss_lag_{l}\" for l in LAGS]\n",
    "\n",
    "roll_feats = [f\"b_roll_{w}\"  for w in ROLLS] + [f\"it_roll_{w}\" for w in ROLLS] + \\\n",
    "             [f\"ds_roll_{w}\" for w in ROLLS] + [f\"ss_roll_{w}\" for w in ROLLS]\n",
    "\n",
    "FEATS = base_feats + lag_feats + roll_feats\n",
    "\n",
    "# Drop righe con NaN feature (solo training)\n",
    "train_df = train_df.dropna(subset=FEATS)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) TRAIN: 28 MODELLI (NON-RECURSIVE) - CALLBACKS LGB 4.x\n",
    "# ----------------------------------------------------------------------------\n",
    "params = {\n",
    "    \"objective\":\"poisson\",\n",
    "    \"metric\":\"rmse\",\n",
    "    \"learning_rate\":0.08,\n",
    "    \"num_leaves\":31,\n",
    "    \"max_depth\":8,\n",
    "    \"feature_fraction\":0.8,\n",
    "    \"bagging_fraction\":0.8,\n",
    "    \"bagging_freq\":1,\n",
    "    \"verbose\":-1,\n",
    "    \"n_jobs\":-1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "print(\"Training 28 modelli\")\n",
    "for h in tqdm(range(1, 29)):\n",
    "    Xh = train_df.copy()\n",
    "    grp = Xh.groupby(\"id\", sort=False)\n",
    "    for col in lag_feats + roll_feats:\n",
    "        Xh[col] = grp[col].shift(h).values\n",
    "\n",
    "    Xh = Xh.dropna(subset=FEATS)\n",
    "    y = Xh[\"sales\"].values\n",
    "    X = Xh[FEATS].values\n",
    "\n",
    "    dtrain = lgb.Dataset(X, y)\n",
    "\n",
    "    models[h] = lgb.train(\n",
    "        params=params,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=N_ROUNDS,\n",
    "        valid_sets=[dtrain],\n",
    "        valid_names=[\"train\"],\n",
    "        callbacks=[lgb.log_evaluation(period=0)]  # sostituisce verbose_eval\n",
    "    )\n",
    "\n",
    "    del Xh, X, y, dtrain\n",
    "    gc.collect()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) PREDICT\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"Predict 28 giorni...\")\n",
    "test_days = sorted(test_df[\"date\"].unique())\n",
    "assert len(test_days) >= 28\n",
    "test_days = test_days[:28]\n",
    "\n",
    "pred_list = []\n",
    "for h, day in tqdm(list(zip(range(1,29), test_days))):\n",
    "    Xtest = test_df[test_df[\"date\"]==day].copy()\n",
    "    Xmat = Xtest[FEATS].fillna(0).values\n",
    "    pred = models[h].predict(Xmat)\n",
    "    out = Xtest[[\"id\"]].copy()\n",
    "    out[\"h\"] = h\n",
    "    out[\"forecast\"] = np.clip(pred, 0, None)\n",
    "    pred_list.append(out)\n",
    "\n",
    "pred_all = pd.concat(pred_list, axis=0)\n",
    "pivot = pred_all.pivot(index=\"id\", columns=\"h\", values=\"forecast\").reindex(\n",
    "    sales[\"id\"].tolist()).fillna(0)\n",
    "pivot.columns = [f\"F{i}\" for i in range(1, 29)]\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7) WRMSSE\n",
    "# ----------------------------------------------------------------------------\n",
    "forecast_array = pivot.values\n",
    "score = wrmsse(forecast_array)\n",
    "print(f\"\\n✅ Hierarchical WRMSSE: {score:.4f}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 8) SALVATAGGIO\n",
    "# ----------------------------------------------------------------------------\n",
    "pivot.to_pickle(OUT_DIR / \"hier_fast_forecasts.pkl\")\n",
    "with open(OUT_DIR / \"hier_fast_summary.pkl\",\"wb\") as f:\n",
    "    pickle.dump({\"wrmsse\": float(score),\n",
    "                 \"history_days\": FAST_HISTORY_DAYS,\n",
    "                 \"lags\": LAGS,\n",
    "                 \"rolls\": ROLLS,\n",
    "                 \"rounds\": N_ROUNDS}, f)\n",
    "print(\"Salvato in hier_fast_results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ae601-eb16-4a24-8b9b-6c07cf72895a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_env",
   "language": "python",
   "name": "mlops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
