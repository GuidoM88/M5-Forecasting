{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eea24e8-f01b-488b-bcc8-fb363ddf9c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MULTI-HORIZON LIGHTGBM\n",
      "================================================================================\n",
      "\n",
      "[1/5] Caricamento dati...\n",
      "✓ Train: (58327370, 11)\n",
      "\n",
      "[2/5] Feature engineering...\n",
      "  Aggregations (2 levels)...\n",
      "  Lag features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Lags: 100%|███████████████████████████████████| 2/2 [00:05<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Rolling features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Rolling: 100%|████████████████████████████████| 2/2 [00:09<00:00,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Features: (58327370, 26)\n",
      "\n",
      "[3/5] Train/test split...\n",
      "Train: (10305620, 26)\n",
      "Test: (853720, 26)\n",
      "Features: 14\n",
      "After dropna - Train: (10305620, 26), Test: (853720, 26)\n",
      "\n",
      "[4/5] Training 28 models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████| 28/28 [04:45<00:00, 10.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ 28 models trained!\n",
      "\n",
      "[5/5] Forecasting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|███████████████████████████████| 28/28 [00:00<00:00, 37.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Forecast array: (30490, 28)\n",
      "✓ Forecast columns: ['F1', 'F2', 'F3', 'F4', 'F5']...\n",
      "\n",
      "Calcolo WRMSSE...\n",
      "\n",
      "✅ WRMSSE: 0.7273\n",
      "✓ Salvato: multihorizon_forecasts.pkl con colonne FX\n",
      "\n",
      "================================================================================\n",
      "COMPLETATO ✅\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Multi-Horizon LightGBM\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from m5_wrmsse import wrmsse\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SETUP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MULTI-HORIZON LIGHTGBM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "RAW_DIR = Path(\"../data/raw\")\n",
    "OUTPUT_DIR = Path(\"../data/multihorizon_results\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CARICA DATI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[1/5] Caricamento dati...\")\n",
    "\n",
    "with open(DATA_DIR / \"train_official.pkl\", 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Train: {train.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[2/5] Feature engineering...\")\n",
    "\n",
    "train = train.sort_values(['id', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Date features\n",
    "train['dayofweek'] = train['date'].dt.dayofweek\n",
    "train['day'] = train['date'].dt.day\n",
    "train['month'] = train['date'].dt.month\n",
    "train['year'] = train['date'].dt.year\n",
    "train['is_weekend'] = (train['dayofweek'] >= 5).astype(int)\n",
    "\n",
    "print(\"  Aggregations (2 levels)...\")\n",
    "# Level 1: Item (tutti gli store)\n",
    "item_agg = train.groupby(['item_id', 'date'])['sales'].mean().reset_index()\n",
    "item_agg.columns = ['item_id', 'date', 'sales_item']\n",
    "train = train.merge(item_agg, on=['item_id', 'date'], how='left')\n",
    "\n",
    "# Level 2: Dept-Store\n",
    "dept_agg = train.groupby(['dept_id', 'store_id', 'date'])['sales'].mean().reset_index()\n",
    "dept_agg.columns = ['dept_id', 'store_id', 'date', 'sales_dept']\n",
    "train = train.merge(dept_agg, on=['dept_id', 'store_id', 'date'], how='left')\n",
    "\n",
    "del item_agg, dept_agg\n",
    "gc.collect()\n",
    "\n",
    "# Lag features \n",
    "print(\"  Lag features...\")\n",
    "for lag in tqdm([7, 28], desc=\"    Lags\"):\n",
    "    train[f'lag_{lag}'] = train.groupby('id')['sales'].shift(lag)\n",
    "    train[f'lag_item_{lag}'] = train.groupby('item_id')['sales_item'].shift(lag)\n",
    "\n",
    "# Rolling features\n",
    "print(\"  Rolling features...\")\n",
    "for window in tqdm([7, 28], desc=\"    Rolling\"):\n",
    "    train[f'roll_{window}'] = train.groupby('id')['sales'].transform(\n",
    "        lambda x: x.shift(1).rolling(window).mean()\n",
    "    )\n",
    "\n",
    "# Encoding\n",
    "train['id_encoded'] = pd.factorize(train['id'])[0]\n",
    "train['dept_encoded'] = pd.factorize(train['dept_id'])[0]\n",
    "\n",
    "print(f\"✓ Features: {train.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[3/5] Train/test split...\")\n",
    "\n",
    "# Usa solo 1 anno di training (più veloce, comunque efficace)\n",
    "DAYS_HISTORY = 365\n",
    "train['day_num'] = (train['date'] - train['date'].min()).dt.days\n",
    "max_day = train['day_num'].max()\n",
    "\n",
    "# Train\n",
    "train_start = max_day - DAYS_HISTORY\n",
    "train_end = max_day - 28\n",
    "\n",
    "X_train = train[(train['day_num'] >= train_start) & \n",
    "                (train['day_num'] <= train_end)].copy()\n",
    "X_test = train[train['day_num'] > train_end].copy()\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'dayofweek', 'day', 'month', 'is_weekend',\n",
    "    'id_encoded', 'dept_encoded',\n",
    "    'sales_item', 'sales_dept',\n",
    "    'lag_7', 'lag_28',\n",
    "    'lag_item_7', 'lag_item_28',\n",
    "    'roll_7', 'roll_28'\n",
    "]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "\n",
    "# Dropna\n",
    "X_train = X_train.dropna(subset=feature_cols)\n",
    "X_test = X_test.dropna(subset=feature_cols)\n",
    "\n",
    "print(f\"After dropna - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "# ============================================================================\n",
    "# 5. TRAIN 28 MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[4/5] Training 28 models...\")\n",
    "\n",
    "params = {\n",
    "    'objective': 'poisson',\n",
    "    'metric': 'rmse',\n",
    "    'learning_rate': 0.1,  \n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 6,        \n",
    "    'feature_fraction': 0.8,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "models = {}\n",
    "\n",
    "for day in tqdm(range(1, 29), desc=\"Training\"):\n",
    "    # Shift features per questo forecast day\n",
    "    X_train_day = X_train.copy()\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        if 'lag' in col or 'roll' in col or col in ['sales_item', 'sales_dept']:\n",
    "            X_train_day[col] = X_train.groupby('id')[col].shift(day)\n",
    "    \n",
    "    # Dropna\n",
    "    X_train_day = X_train_day.dropna(subset=feature_cols)\n",
    "    \n",
    "    # Train\n",
    "    y_train_day = X_train_day['sales']\n",
    "    X_train_features = X_train_day[feature_cols]\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train_features, y_train_day)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100,  # Ridotto per velocità\n",
    "        callbacks=[lgb.log_evaluation(period=0)]\n",
    "    )\n",
    "    \n",
    "    models[f'F{day}'] = model  # ← CHANGED: day_X → FX\n",
    "    \n",
    "    del X_train_day, y_train_day, X_train_features, lgb_train\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\n✓ {len(models)} models trained!\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. FORECAST\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n[5/5] Forecasting...\")\n",
    "\n",
    "# Carica ordine serie\n",
    "sales_orig = pd.read_csv(RAW_DIR / \"sales_train_evaluation.csv\")\n",
    "series_order = sales_orig['id'].tolist()\n",
    "\n",
    "# Qui inserisci:\n",
    "train_days = 1913\n",
    "test_days = 28\n",
    "test_cols = [f'd_{i}' for i in range(train_days + 1, train_days + test_days + 1)]\n",
    "\n",
    "test_actuals = sales_orig[['id'] + test_cols].copy()\n",
    "test_actuals.columns = ['id'] + [f'F{i}' for i in range(1, test_days + 1)]\n",
    "\n",
    "# Per ogni giorno, forecast\n",
    "all_forecasts = []\n",
    "\n",
    "for day in tqdm(range(1, 29), desc=\"Predicting\"):\n",
    "    # Test per questo giorno\n",
    "    test_day = X_test[X_test['day_num'] == (max_day - 28 + day)].copy()\n",
    "    \n",
    "    if len(test_day) == 0:\n",
    "        # Fallback: usa ultimo giorno disponibile\n",
    "        test_day = X_test.copy()\n",
    "    \n",
    "    X_test_features = test_day[feature_cols].fillna(0)\n",
    "    \n",
    "    model = models[f'F{day}']  \n",
    "    preds = model.predict(X_test_features)\n",
    "    preds = np.maximum(preds, 0)\n",
    "    \n",
    "    # Map predictions to series\n",
    "    test_day['forecast'] = preds\n",
    "    day_forecasts = test_day.groupby('id')['forecast'].first()\n",
    "    \n",
    "    all_forecasts.append(day_forecasts)\n",
    "\n",
    "# Combine in DataFrame (30490, 28)\n",
    "forecast_df = pd.DataFrame(all_forecasts).T\n",
    "forecast_df.columns = [f'F{i}' for i in range(1, 29)]  # ← CHANGED: day_X → FX\n",
    "\n",
    "# Reindex\n",
    "forecast_df = forecast_df.reindex(series_order).fillna(0)\n",
    "forecast_array = forecast_df.values\n",
    "\n",
    "print(f\"✓ Forecast array: {forecast_array.shape}\")\n",
    "print(f\"✓ Forecast columns: {forecast_df.columns.tolist()[:5]}...\")  # Debug\n",
    "\n",
    "# ============================================================================\n",
    "# 7. WRMSSE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nCalcolo WRMSSE...\")\n",
    "\n",
    "wrmsse_score = wrmsse(forecast_array)\n",
    "\n",
    "print(f\"\\n✅ WRMSSE: {wrmsse_score:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 8. SALVATAGGIO\n",
    "# ============================================================================\n",
    "\n",
    "forecast_df_with_id = forecast_df.copy()\n",
    "forecast_df_with_id['id'] = series_order\n",
    "forecast_df_with_id = forecast_df_with_id[['id'] + [f'F{i}' for i in range(1, 29)]]\n",
    "\n",
    "forecast_df_with_id.to_pickle(OUTPUT_DIR / 'multihorizon_forecasts.pkl')\n",
    "print(f\"✓ Salvato: multihorizon_forecasts.pkl con colonne FX\")\n",
    "\n",
    "summary = {\n",
    "    'wrmsse': wrmsse_score,\n",
    "    'n_models': 28,\n",
    "    'approach': 'multi-horizon'\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / 'multihorizon_summary.pkl', 'wb') as f:\n",
    "    pickle.dump(summary, f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETATO ✅\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_env",
   "language": "python",
   "name": "mlops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
